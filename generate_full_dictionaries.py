
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª–Ω—ã—Ö —Å–ª–æ–≤–∞—Ä–µ–π –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ —Å–æ —Å–∫–ª–æ–Ω–µ–Ω–∏—è–º–∏
–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–∞—Ä—Ç–∏–∏ part_1 - part_7 –∏ —Å–æ–∑–¥–∞—ë—Ç –∫–∞—Ç–∞–ª–æ–≥–∏ part_[N]_full
"""

import pymorphy3
import re
from pathlib import Path
from typing import List, Set

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
morph = pymorphy3.MorphAnalyzer()

def parse_dictionary_file(filepath: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞ —Å–ª–æ–≤–∞—Ä—è Gboard"""
    terms = []
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            if line.startswith('#') or not line:
                continue
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ—Ä–º–∏–Ω (–≤—Ç–æ—Ä–æ–µ –ø–æ–ª–µ –ø–æ—Å–ª–µ TAB)
            parts = line.split('\t')
            if len(parts) >= 2 and parts[1]:
                terms.append(parts[1])
    return terms

def is_capitalizable(term: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ —Ç–µ—Ä–º–∏–Ω —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã"""
    return term and term[0].isupper()

def capitalize_if_needed(word: str, original_word: str) -> str:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä –ø–µ—Ä–≤–æ–π –±—É–∫–≤—ã –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ"""
    if is_capitalizable(original_word):
        return word.capitalize()
    return word.lower()

def inflect_single_word(word: str, case: str, number: str, original_word: str) -> str:
    """
    –°–∫–ª–æ–Ω—è–µ—Ç –æ–¥–Ω–æ —Å–ª–æ–≤–æ
    case: 'nomn', 'gent', 'datv', 'accs', 'ablt', 'loct'
    number: 'sing', 'plur'
    """
    parsed = morph.parse(word.lower())[0]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–∫–ª–æ–Ω—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ
    if 'NOUN' not in parsed.tag and 'ADJF' not in parsed.tag and 'NPRO' not in parsed.tag:
        # –î–ª—è –Ω–µ—Å–∫–ª–æ–Ω—è–µ–º—ã—Ö —Å–ª–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—É—é —Ñ–æ—Ä–º—É
        return capitalize_if_needed(word, original_word)

    try:
        inflected = parsed.inflect({case, number})
        if inflected:
            result = inflected.word
            return capitalize_if_needed(result, original_word)
    except:
        pass

    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—Å–∫–ª–æ–Ω—è—Ç—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—É—é —Ñ–æ—Ä–º—É
    return capitalize_if_needed(word, original_word)

def inflect_phrase(phrase: str) -> Set[str]:
    """
    –°–∫–ª–æ–Ω—è–µ—Ç —Ñ—Ä–∞–∑—É –ø–æ –≤—Å–µ–º –ø–∞–¥–µ–∂–∞–º –∏ —á–∏—Å–ª–∞–º
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤—Å–µ—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–æ—Ä–º
    """
    cases = ['nomn', 'gent', 'datv', 'accs', 'ablt', 'loct']
    numbers = ['sing', 'plur']

    forms = set()
    words = phrase.split()

    for number in numbers:
        for case in cases:
            inflected_words = []
            for word in words:
                inflected = inflect_single_word(word, case, number, word)
                inflected_words.append(inflected)

            inflected_phrase = ' '.join(inflected_words)
            forms.add(inflected_phrase)

    return forms

def should_skip_plural(term: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ –¥–ª—è —Ç–µ—Ä–º–∏–Ω–∞
    –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–ª—è –Ω–µ–∏–∑–º–µ–Ω—è–µ–º—ã—Ö —Å–ª–æ–≤ –∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã—Ö –ø–æ–Ω—è—Ç–∏–π
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ —Ç–µ—Ä–º–∏–Ω–∞
    first_word = term.split()[0].lower()
    parsed = morph.parse(first_word)[0]

    # –ï—Å–ª–∏ —Å–ª–æ–≤–æ –Ω–µ —Å–∫–ª–æ–Ω—è–µ—Ç—Å—è (–Ω–µ–∏–∑–º–µ–Ω—è–µ–º–æ–µ)
    if parsed.tag.POS not in ['NOUN', 'ADJF', 'NPRO']:
        return True

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É —Å–ª–æ–≤–∞ —Ñ–æ—Ä–º–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —á–∏—Å–ª–∞
    plural_form = parsed.inflect({'plur', 'nomn'})
    if not plural_form:
        return True

    return False

def generate_full_dictionary(input_file: str, output_file: str):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Å–æ —Å–∫–ª–æ–Ω–µ–Ω–∏—è–º–∏"""
    print(f"\nüìñ –û–±—Ä–∞–±–æ—Ç–∫–∞: {input_file}")

    # –ß–∏—Ç–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
    terms = parse_dictionary_file(input_file)
    print(f"   –ù–∞–π–¥–µ–Ω–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {len(terms)}")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Å–µ —Å–ª–æ–≤–æ—Ñ–æ—Ä–º—ã
    all_forms = set()

    for term in terms:
        # –î–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—É—é —Ñ–æ—Ä–º—É
        all_forms.add(term)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∫–ª–æ–Ω–µ–Ω–∏—è
        inflected = inflect_phrase(term)

        # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ, —Ñ–∏–ª—å—Ç—Ä—É–µ–º
        if should_skip_plural(term):
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ñ–æ—Ä–º—ã –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —á–∏—Å–ª–∞
            cases = ['nomn', 'gent', 'datv', 'accs', 'ablt', 'loct']
            sing_forms = set()
            words = term.split()

            for case in cases:
                inflected_words = []
                for word in words:
                    infl = inflect_single_word(word, case, 'sing', word)
                    inflected_words.append(infl)
                sing_forms.add(' '.join(inflected_words))

            all_forms.update(sing_forms)
        else:
            all_forms.update(inflected)

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    sorted_forms = sorted(all_forms)

    print(f"   –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Å–ª–æ–≤–æ—Ñ–æ—Ä–º: {len(sorted_forms)}")

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# Gboard Dictionary version:2\n")
        f.write("# Gboard Dictionary format:shortcut\tword\tlanguage_tag\tpos_tag\n")
        for form in sorted_forms:
            f.write(f"\t{form}\tru-RU\t\n")

    print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_file}")
    return len(sorted_forms)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö –ø–∞—Ä—Ç–∏–π"""
    print("="*80)
    print("–ì–ï–ù–ï–†–ê–¶–ò–Ø –ü–û–õ–ù–´–• –°–õ–û–í–ê–†–ï–ô –°–û –°–ö–õ–û–ù–ï–ù–ò–Ø–ú–ò")
    print("="*80)

    # –ü–∞—Ä—Ç–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: part_1, part_2, ..., part_7
    partitions = [
        ('part_1', 'dictionary.txt', 'part_1_full'),
        ('part_2', 'dictionary.txt', 'part_2_full'),
        ('part_3', 'dictionary.txt', 'part_3_full'),
        ('part_4', 'dictionary.txt', 'part_4_full'),
        ('part_5', 'dictionary.txt', 'part_5_full'),
        ('part_6', 'dictionary.txt', 'part_6_full'),
        ('part_7', 'dictionary.txt', 'part_7_full'),
    ]

    total_forms = 0

    for part_name, dict_file, output_dir_name in partitions:
        # –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        input_path = f"{part_name}/{dict_file}"

        # –°–æ–∑–¥–∞—ë–º –∫–∞—Ç–∞–ª–æ–≥ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è
        Path(output_dir_name).mkdir(exist_ok=True)

        # –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        output_path = f"{output_dir_name}/dictionary.txt"

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å
        forms_count = generate_full_dictionary(input_path, output_path)
        total_forms += forms_count

    print("\n" + "="*80)
    print(f"–í–°–ï–ì–û –°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù–û: {total_forms} —Å–ª–æ–≤–æ—Ñ–æ—Ä–º")
    print("="*80)

if __name__ == "__main__":
    main()
