#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ–ª–Ω—ã—Ö —Å–ª–æ–≤–∞—Ä–µ–π –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç part_1_full - part_7_full –≤ dict_full/dictionary.txt

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
python merge_dictionaries.py
"""

<<<<<<< Updated upstream
import pymorphy2, pymorphy3
import re
=======
>>>>>>> Stashed changes
from pathlib import Path
from typing import Set

def parse_dictionary_file(filepath: str) -> Set[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞ —Å–ª–æ–≤–∞—Ä—è Gboard"""
<<<<<<< Updated upstream
    terms = []
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            # –£–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥ —Å—Ç—Ä–æ–∫–∏, –Ω–æ –ù–ï —Ç–∞–±—ã
            line = line.rstrip('\r\n')
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            if line.startswith('#') or not line:
                continue
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ—Ä–º–∏–Ω (–≤—Ç–æ—Ä–æ–µ –ø–æ–ª–µ –ø–æ—Å–ª–µ TAB)
            parts = line.split('\t')
            if len(parts) >= 2 and parts[1]:
                terms.append(parts[1])
    return terms

def is_capitalizable(term: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ —Ç–µ—Ä–º–∏–Ω —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã"""
    return term and term[0].isupper()

def capitalize_if_needed(word: str, original_word: str) -> str:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä –ø–µ—Ä–≤–æ–π –±—É–∫–≤—ã –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ"""
    if is_capitalizable(original_word):
        return word.capitalize()
    return word.lower()

def inflect_single_word(word: str, case: str, number: str, original_word: str) -> str:
    """
    –°–∫–ª–æ–Ω—è–µ—Ç –æ–¥–Ω–æ —Å–ª–æ–≤–æ
    case: 'nomn', 'gent', 'datv', 'accs', 'ablt', 'loct'
    number: 'sing', 'plur'
    """
    parsed = morph.parse(word.lower())[0]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–∫–ª–æ–Ω—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ
    if 'NOUN' not in parsed.tag and 'ADJF' not in parsed.tag and 'NPRO' not in parsed.tag:
        # –î–ª—è –Ω–µ—Å–∫–ª–æ–Ω—è–µ–º—ã—Ö —Å–ª–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—É—é —Ñ–æ—Ä–º—É
        return capitalize_if_needed(word, original_word)

    try:
        inflected = parsed.inflect({case, number})
        if inflected:
            result = inflected.word
            return capitalize_if_needed(result, original_word)
    except:
        pass

    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—Å–∫–ª–æ–Ω—è—Ç—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—É—é —Ñ–æ—Ä–º—É
    return capitalize_if_needed(word, original_word)

def inflect_phrase(phrase: str) -> Set[str]:
    """
    –°–∫–ª–æ–Ω—è–µ—Ç —Ñ—Ä–∞–∑—É –ø–æ –≤—Å–µ–º –ø–∞–¥–µ–∂–∞–º –∏ —á–∏—Å–ª–∞–º
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤—Å–µ—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–æ—Ä–º
    """
    cases = ['nomn', 'gent', 'datv', 'accs', 'ablt', 'loct']
    numbers = ['sing', 'plur']

    forms = set()
    words = phrase.split()

    for number in numbers:
        for case in cases:
            inflected_words = []
            for word in words:
                inflected = inflect_single_word(word, case, number, word)
                inflected_words.append(inflected)

            inflected_phrase = ' '.join(inflected_words)
            forms.add(inflected_phrase)

    return forms

def should_skip_plural(term: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ –¥–ª—è —Ç–µ—Ä–º–∏–Ω–∞
    –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–ª—è –Ω–µ–∏–∑–º–µ–Ω—è–µ–º—ã—Ö —Å–ª–æ–≤ –∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã—Ö –ø–æ–Ω—è—Ç–∏–π
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ —Ç–µ—Ä–º–∏–Ω–∞
    first_word = term.split()[0].lower()
    parsed = morph.parse(first_word)[0]

    # –ï—Å–ª–∏ —Å–ª–æ–≤–æ –Ω–µ —Å–∫–ª–æ–Ω—è–µ—Ç—Å—è (–Ω–µ–∏–∑–º–µ–Ω—è–µ–º–æ–µ)
    if parsed.tag.POS not in ['NOUN', 'ADJF', 'NPRO']:
        return True

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É —Å–ª–æ–≤–∞ —Ñ–æ—Ä–º–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —á–∏—Å–ª–∞
    plural_form = parsed.inflect({'plur', 'nomn'})
    if not plural_form:
        return True

    return False

def generate_full_dictionary(input_file: str, output_file: str):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Å–æ —Å–∫–ª–æ–Ω–µ–Ω–∏—è–º–∏"""
    print(f"\n[*] –û–±—Ä–∞–±–æ—Ç–∫–∞: {input_file}")

    # –ß–∏—Ç–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
    terms = parse_dictionary_file(input_file)
    print(f"   –ù–∞–π–¥–µ–Ω–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {len(terms)}")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Å–µ —Å–ª–æ–≤–æ—Ñ–æ—Ä–º—ã
    all_forms = set()

    for term in terms:
        # –î–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—É—é —Ñ–æ—Ä–º—É
        all_forms.add(term)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∫–ª–æ–Ω–µ–Ω–∏—è
        inflected = inflect_phrase(term)

        # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ, —Ñ–∏–ª—å—Ç—Ä—É–µ–º
        if should_skip_plural(term):
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ñ–æ—Ä–º—ã –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —á–∏—Å–ª–∞
            cases = ['nomn', 'gent', 'datv', 'accs', 'ablt', 'loct']
            sing_forms = set()
            words = term.split()

            for case in cases:
                inflected_words = []
                for word in words:
                    infl = inflect_single_word(word, case, 'sing', word)
                    inflected_words.append(infl)
                sing_forms.add(' '.join(inflected_words))

            all_forms.update(sing_forms)
=======
    terms = set()
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫, —Å–æ—Ö—Ä–∞–Ω—è—è \t
                line = line.rstrip('\r\n')
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                if line.startswith('#') or not line.strip():
                    continue
                    
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ—Ä–º–∏–Ω (–≤—Ç–æ—Ä–æ–µ –ø–æ–ª–µ –ø–æ—Å–ª–µ TAB)
                parts = line.split('\t')
                
                # –§–æ—Ä–º–∞—Ç Gboard: shortcut \t word \t language \t pos
                if len(parts) >= 2 and parts[1].strip():
                    terms.add(parts[1].strip())
                    
    except FileNotFoundError:
        print(f"   ‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}")
    
    return terms

def merge_all_dictionaries():
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ —Å–ª–æ–≤–∞—Ä–∏ –≤ –æ–¥–∏–Ω"""
    print("="*80)
    print("–û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –í–°–ï–• –°–õ–û–í–ê–†–ï–ô –í –û–î–ò–ù –§–ê–ô–õ")
    print("="*80)
    
    partitions = [
        'part_1_full',
        'part_2_full',
        'part_3_full',
        'part_4_full',
        'part_5_full',
        'part_6_full',
        'part_7_full',
    ]
    
    all_terms = set()
    stats_counts = {}  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ö—ç—à–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è
    
    for part_name in partitions:
        dict_path = f"{part_name}/dictionary.txt"
        print(f"\nüìñ –ß—Ç–µ–Ω–∏–µ: {dict_path}")
        
        terms = parse_dictionary_file(dict_path)
        stats_counts[part_name] = len(terms)
        
        if terms:
            print(f"   –ù–∞–π–¥–µ–Ω–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {len(terms)}")
            all_terms.update(terms)
>>>>>>> Stashed changes
        else:
            print(f"   ‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
    
    print(f"\nüìä –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤: {len(all_terms)}")
    
    # –°–æ–∑–¥–∞—ë–º –≤—ã—Ö–æ–¥–Ω–æ–π –∫–∞—Ç–∞–ª–æ–≥
    output_dir = Path("dict_full")
    output_dir.mkdir(exist_ok=True)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–µ—Ä–º–∏–Ω—ã
    sorted_terms = sorted(all_terms)
    output_file = output_dir / "dictionary.txt"
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# Gboard Dictionary version:2\n")
        f.write("# Gboard Dictionary format:shortcut\tword\tlanguage_tag\tpos_tag\n")
<<<<<<< Updated upstream
        for form in sorted_forms:
            f.write(f"\t{form}\tru-RU\t\n")

    print(f"   [OK] –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_file}")
    return len(sorted_forms)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö –ø–∞—Ä—Ç–∏–π"""
    print("="*80)
    print("–ì–ï–ù–ï–†–ê–¶–ò–Ø –ü–û–õ–ù–´–• –°–õ–û–í–ê–†–ï–ô –°–û –°–ö–õ–û–ù–ï–ù–ò–Ø–ú–ò")
    print("="*80)

    # –ü–∞—Ä—Ç–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: part_1, part_2, ..., part_7
    partitions = [
        ('part_1', 'dictionary.txt', 'part_1_full'),
        ('part_2', 'dictionary.txt', 'part_2_full'),
        ('part_3', 'dictionary.txt', 'part_3_full'),
        ('part_4', 'dictionary.txt', 'part_4_full'),
        ('part_5', 'dictionary.txt', 'part_5_full'),
        ('part_6', 'dictionary.txt', 'part_6_full'),
        ('part_7', 'dictionary.txt', 'part_7_full'),
    ]

    total_forms = 0

    for part_name, dict_file, output_dir_name in partitions:
        # –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        input_path = f"{part_name}/{dict_file}"

        # –°–æ–∑–¥–∞—ë–º –∫–∞—Ç–∞–ª–æ–≥ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è
        Path(output_dir_name).mkdir(exist_ok=True)

        # –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        output_path = f"{output_dir_name}/dictionary.txt"

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å
        forms_count = generate_full_dictionary(input_path, output_path)
        total_forms += forms_count

=======
        f.write(f"# –ü–æ–ª–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ —Å–æ —Å–∫–ª–æ–Ω–µ–Ω–∏—è–º–∏\n")
        f.write(f"# –í—Å–µ–≥–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {len(sorted_terms)}\n")
        
        for term in sorted_terms:
            f.write(f"\t{term}\tru-RU\t\n")
    
    print(f"\n‚úÖ –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_file}")
    print(f"   –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(sorted_terms)}")
    
    # –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    stats_file = output_dir / "statistics.txt"
    
    with open(stats_file, 'w', encoding='utf-8') as f:
        f.write("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–™–ï–î–ò–ù–Å–ù–ù–û–ì–û –°–õ–û–í–ê–†–Ø\n")
        f.write("="*80 + "\n\n")
        f.write(f"–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤–æ—Ñ–æ—Ä–º: {len(sorted_terms)}\n\n")
        f.write("–ò—Å—Ç–æ—á–Ω–∏–∫–∏:\n")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        for part_name in partitions:
            f.write(f"  - {part_name}: {stats_counts[part_name]} —Ç–µ—Ä–º–∏–Ω–æ–≤\n")
        
        f.write(f"\n–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: dict_full/dictionary.txt\n")
        f.write(f"–§–æ—Ä–º–∞—Ç: Gboard Dictionary (–¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –≤ Gboard)\n")
    
    print(f"‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {stats_file}")
>>>>>>> Stashed changes
    print("\n" + "="*80)
    print("–ì–û–¢–û–í–û!")
    print("="*80)
    print(f"\nüìÇ –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å: dict_full/dictionary.txt")
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: dict_full/statistics.txt")
    print(f"\nüí° –ò–º–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ dict_full/dictionary.txt –≤ Gboard –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è!")

if __name__ == "__main__":
    merge_all_dictionaries()
